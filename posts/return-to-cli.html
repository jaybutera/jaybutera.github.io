<html>
    <head>
        <!--<link rel="stylesheet" href="../tufte.css"/>-->
        <link rel="stylesheet" href="../styles.css"/>
        <meta charset="UTF-8"/>
        <title>A Case For the Return to Command Line</title>
    </head>
    <body>
        <div id="article-body">
            <h1>A Case For the Return to Command Line</h1>
            <p>In this article I hope to help you see an alternative possible relationship<br/>with the software we use. One where software is built more personally; like a<br/>hand-crafted clock rather than a mass-manufactured shoe.</p><p>To see how this is possible, we’ll look at the history of computing, going back<br/>to AT&amp;T Bell Labs. We’ll also look at the modern software ecosystem, and the<br/>differences between consumer-grade software, and the sort of “deep web” underbelly<br/>of software that exists on GitHub; inacessible to the average user.</p><p>This is not a romanticization of the good ol’ days of computing. There are very<br/>practical reasons to investigate modern notions of user-interfaces. The modern<br/>notion of software is that it is complex and requires teams of engineers to<br/>design and constantly maintain throughout the life of the software.</p><p>Building an alternative web browser, one not based on Firefox or Chrome, is an<br/>enormous task that would require a sustainable business to maintain. Similarly,<br/>better collaboration tools than Google Drive or the alternatives like Cryptpad<br/>are highly desirable but also require a team of engineers to manage.</p><p>Software has become complex and difficult to build and maintain. But there are<br/>pockets of history where we can see a much more personal and useful evolution<br/>of software shine through the muck. Bell Labs is a well known R&amp;D branch of<br/>AT&amp;T which produced an uncanny amount of modern technology between the<br/>1960-80s. To name a few, the transistor, information theory, the Unix operating<br/>system (the foundation of Linux and MacOS), the C programming language,<br/>cellular networks, the laser, and even the first evidence of the cosmic<br/>microwave background radiation was accidently discovered at Bell Labs.</p><p>Within the computing department of Bell Labs alone, the majority of<br/>foundational software tools used today, that are almost unnoticed when using a<br/>computer, were built for internal use. One such tool was Bash - a text based<br/>interactive environment to the operating system, aka “command line”.</p><p>Researchers built their software to be used in bash. Everyone at Bell Labs as<br/>well as the other branches of AT&amp;T used software built by the researchers. For<br/>instance the first application of Unix was an automation tool for AT&amp;T patent<br/>writers, who were submitting multiple patents a day.</p><p>This kind of tight-knit relationship between developers and users enabled a<br/>rapid evolution of highly effective software. Software developers were building<br/>software for their own use, and getting feedback from others using the software<br/>as well. As a result the lab produced some of the finest quality software,<br/>evidenced by its proliferant use today, more than half a century later.</p><p>The close relationship between development and use is certainly what enabled<br/>the incredible pace of the lab to innovate. As another example, after the<br/>compiler frontend Yacc was made, which is essentially a tool to automate<br/>compiler design, others used it to make tools like the portable C<br/>compiler, Make, and Roff. All of which are still commonly used today, including Yacc<br/>itself.</p><p>It’s worth noting here that just because software is old does not mean it is<br/>less complex than modern-day software. In fact Unix is a response to<br/>a long-standing bureaucratic operating system project called Multics. Multics<br/>was heavily over engineered. It was a costly and time consuming project. After<br/>finishing work on it, Ken Thompson reflected on what went wrong and built<br/>Unix in three weeks.</p><p>We distinguish between quality software made in close connection with users and<br/>software which is made to reach a vague and sweeping audience, likely for<br/>reasons of profit, by calling them polytechnic and monotechnic software<br/>respectively. These are terms coined by <a href="https://postrev.wordpress.com/2009/07/09/technics/">Lewis Mumford</a>.</p><p>Back to the modern day, a similar caliber of a quality software ecosystem still<br/>exists but it is hidden from most people. Such software is reserved only for<br/>developers and “power” users that know how to use the command line. Using these<br/>tools, seemingly difficult problems for most people today become easy.<br/>Collaborating on documents without the use of a central server, sending large<br/>files over the internet, and staying private in web interactions are all common<br/>operations in polytechnic software.</p><p>The reason these tools only exist on command line is that building a graphical<br/>interface for them would be a project in itself, likely just as complex or more<br/>than the software itself. In order to reach all platforms at once, html on the<br/>web is a common choice for a GUI. But choosing this route also ties the<br/>software to the web paradigm which is an unhelpful abstraction for the<br/>use cases just mentioned.</p><p>It is also an illusion that web apps work universally on all platforms.<br/>Discrepancies between rendering in Firefox and Chrome, and even<br/>different versions of the browser or different operating systems and devices<br/>all have to be considered. The product becomes mediocre software which is complex to<br/>maintain. A jack of all trades and master of none.</p><p>This is why some of the most useful software is crafted for command line. It<br/>fits into an environment which has hardly changed since its conception many<br/>decades ago. It can be composed with the other common tools in the command line<br/>“toolbox” rather than being a one-off project which requires an entirely new<br/>ecosystem to be built around it. And finally the environment is the same on all<br/>systems.</p><p>This all saves time and energy for the developer, so that the focus is on the<br/>actual logic and intention of the software. It is this ability to rapidly<br/>iterate which closes the gap between developer and user. This is a tenet for<br/>quality software which designs for users rather than vaguely at them. This is<br/>the difference between polytechnic and monotechnics.</p><p>It is a common pattern today in small companies that the engineers design tools<br/>for the “end user” who typically is outside the company. This is not<br/>necessarily the case in large companies, like Google, which have many software<br/>tools built for internal use.</p><p>In the small company, the business development team, marketing team, research<br/>team, etc. are all not benefitting directly from the software produced by the<br/>engineers. At best the teams benefit as much as anyone else who is using the<br/>tools designed for the mass “end users”, which as described before is often<br/>mediocre compared to polytechnic software.</p><p>Furthermore you typically see that amongst the engineers they are sharing<br/>software with one another and providing feedback, and building off eachothers work.</p><p>An organization which is able to engineer carefully curated software for its<br/>needs through a tight feedback loop between development and use will be highly<br/>effective. For such a team, software will become the means rather than the end.<br/>That is, the software will support exponential progress in all focal points of a<br/>project.</p><p>In order to produce and utilize polytechnic software, we have to reconsider the<br/>users relationship with it. We must see software not necessarily as<br/>something that is written once for everyone and then maintained, but instead<br/>acknowledge that it is built in the context of an environment which dictates its<br/>features. Usually that environment is a small team; a lab or company.</p><p>It is not the aim of polytechnic software to reach a large audience quickly,<br/>although sometimes it does, like in the case of Unix. The goal is to serve the<br/>needs of the environment.</p><p>Therefore we should not consider software to be a failure if not just anyone<br/>can pick it up and use it right away (being “user friendly”). It only needs to<br/>empower and serve the use cases in its environment. It is up to both the users<br/>and the software to achieve that goal in a synergy rather than the software<br/>extending until it is so universal that most of the features have been hidden<br/>away and the software is bogged down in complexity.</p><p>Developing tools for the command line allows software to evolve rapidly, and<br/>for the focus to be on the uses rather than appearances. The argument made here<br/>for the benefits of command line have mostly been made from empirical data from<br/>history and the modern open source ecosystem.</p><p>This is not to say that command line is necessarily the pinnacle of the polytechnic<br/>software user experience. Only that historically and still today it is the most<br/>effective way to make software usable and efficient.</p><p>There may be innovative solutions in the future which excel programmers and<br/>users alike beyond the terminal. But for now the command line only needs to be<br/>re-discovered, as the reasons for its usefulness have been forgotten by all but<br/>the fringe users of software.</p>
        </div>
    </body>
</html>